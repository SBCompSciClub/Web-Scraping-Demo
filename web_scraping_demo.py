# -*- coding: utf-8 -*-
"""Web Scraping Demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vkOyOaWCjf3OphvKsS-tm28S9FDrFJyi

# Web Scraping and Python Basics

## Python Variables and Data Types

### Numbers
"""

x = 0
y = 1
z = 2
print(x, y, z) # printing all the variables
x += 2 # increase x by 2
print(x) 
print(x / 2 + y * z) # order of operations
print(type(x), type(x/2)) # int vs float

"""### Strings"""

s = "Hello World"
print(s)
s += '!' # adding to a string, can use both double and single quotes
s += str(x) # int to string
print(s)
s = "10" 
print(int(s), float(s)) # string to int and float

"""### Lists"""

l = [1, 2, 3, 4] # create a python list
print(l)

# Indexing
print(l[0])
print(l[1:])
print(l[:-2])
print(l[1:2])

"""### For Loops
These are for looping through iterable objects like lists
"""

for i in l:
  print(i)
print() 
 
for i in range(10):
  print(i)

"""### Functions
Let's make a function to print each element in a list
"""

def print_list(lis):
  for obj in lis:
    print(obj)
  print()
  
print_list(l)

"""## Package Manager

pip is a python package manager that lets you use libraries that other people have made. For this demo we will need a library called Beautiful Soup to parse some html for us. So we will install it using this:
"""

!pip install bs4

"""## Basic Setup

Import all of the libraries we will use
"""

from bs4 import BeautifulSoup
import urllib.request

"""Set up some constants like the [url](https://news.google.com/?hl=en-US&gl=US&ceid=US:en) we will scrape, the word we are searching for, and the maximum amount of results we want"""

url = "https://news.google.com/?hl=en-US&gl=US&ceid=US:en"
max_results = 3
keyword = "Trump"

"""## Web Scraping
We will scrape all of the headlines containing "Trump" from Google News

Request for the html content and send it to a BeautifulSoup object
"""

page = urllib.request.urlopen(url) # request for the websites content
    
soup = BeautifulSoup(page, 'html.parser') # give it to our html parser
print(soup)

print(type(soup))

"""Now let's take find all of the headlines (h3 elements)"""

headlines = soup.find_all('h3') # finds all the headlines
print_list(headlines)

"""Now, filter out any headlines that do not contain Trump"""

trump_headlines = []
for headline in headlines:
  if keyword in headline.getText(): # checks if our keyword is in the text of the headline element
    trump_headlines.append(headline.getText()) # adds it to our list
print_list(trump_headlines)

"""Now lets only show a certain amount of results (according to our max results variable)"""

print_list(trump_headlines[:max_results]) # only shows the first few elements (according to max_results)